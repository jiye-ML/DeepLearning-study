* [paper](paper/22.10-02-18-A-bayesian-perspective-on-generalization-and-stochastic-gradient-descent.pdf)



* [Deep Learning中的Large Batch Training相关理论与实践](https://www.cnblogs.com/deep-learning-stacks/p/10296637.html)
  *  所以，我们得到了结论，SGD引入了一些Noise，这个Noise具有一定的Flucturate，它的大小是和Batch Size成反比，与Learning Rate成正比。 