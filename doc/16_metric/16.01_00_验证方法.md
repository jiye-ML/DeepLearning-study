# Sklearn_GridSearchCV

* GridSearchCV 用于系统地遍历多种参数组合，通过交叉验证确定最佳效果参数。它的好处是，只需增加几行代码，就能遍历多种组合。

* 下面是来自 sklearn 文档 的一个示例：
```
parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}
svr = svm.SVC()
clf = grid_search.GridSearchCV(svr, parameters)
clf.fit(iris.data, iris.target)

```
* 让我们逐行进行说明。
    * `parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}`
        * 参数字典以及他们可取的值。在这种情况下，他们在尝试找到 kernel（可能的选择为 'linear' 和 'rbf' ）和 C（可能的选择为1和10）
        的最佳组合。这时，会自动生成一个不同（kernel、C）参数值组成的“网格”:
        ('rbf', 1)	('rbf', 10)  ('linear', 1)	('linear', 10)
        * 各组合均用于训练 SVM，并使用交叉验证对表现进行评估。
        
    * `svr = svm.SVC()` :这与创建分类器有点类似，就如我们从第一节课一直在做的一样。
    但是请注意，“clf” 到下一行才会生成—这儿仅仅是在说采用哪种算法。另一种思考方法是，“分类器”在这种情况下不仅仅是一个算法，
    而是算法加参数值。请注意，这里不需对 kernel 或 C 做各种尝试；下一行才处理这个问题。

    * `clf = grid_search.GridSearchCV(svr, parameters)`:v这是第一个不可思议之处，分类器创建好了。
     我们传达算法 (svr) 和参数 (parameters) 字典来尝试，它生成一个网格的参数组合进行尝试。

    * `clf.fit(iris.data, iris.target)` ：第二个不可思议之处。 拟合函数现在尝试了所有的参数组合，并返回一个合适的分类器，
    自动调整至最佳参数组合。现在您便可通过 clf.best_params_ 来获得参数值。